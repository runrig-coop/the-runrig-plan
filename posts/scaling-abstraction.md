---
title: Against Scale
subtitle: The cloud falling back down to earth
description: A look at the way scalability perpetuates some of the worst
    tendencies of neoliberal capitalism, and how Runrig proposes to overturn
    those harmful dynamics through participatory design and transparent
    abstractions.
author: Jamie Gaehring
date: 2025-07-29
---

In Silicon Valley, there is a widespread fascination with _scaling_, or to be
more precise, _digital technologies that scale_. The verb "to scale" in this
context can take the passive voice, as in digital technologies that "can be
scaled," or an active voice for technologies that facilitate "the scaling of"
other systems, both digital and non-digital systems alike. If some new tech
promises "to scale" and "to be scaled" at the same time, all the better. Many a
would-be founder has exalted the properties of this or that technology for its
ability to scale, as if by some quasi-magical property latent in the computer
chips themselves. But scaling is by no means inherent to the nature of
computation, nor does scaling emerge from digital technology all of its own
accord. Rather, it is imposed on technology by a mandate from venture capital
investors to pursue unlimited economic growth.

For its own part, information technology does make an original contribution in
the form of its unrivaled capacity for _abstraction_, a power that can just as
well be applied to scaling as to other unrelated tasks or even opposing aims. A
well-designed computer algorithm can abstract away concrete details of the real
world – e.g., material goods and services, users, workers, facial expressions,
social relations, monetary costs, or environmental costs – and whisk them away
to the _cloud_. Once in this realm of pure abstraction, properties like color,
size, and shape become mere numbers or bits. Free of all physical encumbrance,
our worldly cares assume new virtual bodies, becoming weightless, untethered,
and without consequence. Up there in the cloud, scale itself is only limited to
the largest number you can fit into a [64-bit register] – although that limit,
too, can be easily abstracted away.

[64-bit register]:
    https://tromp.github.io/blog/2023/11/24/largest-number

When the object of scaling is economic productivity or market dynamics,
computational abstraction becomes an accelerant for capital's race towards
infinite growth. This secret sauce – abstraction coupled to a business model
meant for rapid market growth and capital accumulation – is what business
analysts or techno-optimists typically infer by the neologism: _scalability_.

## The Physicality of Information
Before going too much further, I should point out that in addition to the
economic sense of the word, scalability has another more technical usage, where
scale can be measured by empirical observation or even evaluated by mathematical
proof.[^comp-sci] Some might argue that this technical meaning can be considered
independently from its business connotation, without any reference to
socioeconomic value statements. That may be true in a purely academic setting,
but even under such contrived circumstances, I would argue that the term still
comes freighted with some heavy socioeconomic implications. The physical limits
and potentials of scalability measured in the laboratory are of interest largely
to the extent that they can be correlated to the economic costs and benefits of
scalability. There is no applied science for the upper reaches of scalability
without the vast resources available only to tech companies intent on scaling to
billions of users and a market capitalization that puts them on the S&P 500.
That's what funds scientific research into scalability in the first and why it
gets any significant attention.

[^comp-sci]: Scalability is a pretty dry body of literature in the applied
    sciences, but to get a sense, see [Amdahl's Law] and [Gunther's Universal
    Scalability Law]. The theoretical physics behind computational limits is
    actually a lot more approachable and fun to explore. On her YouTube channel
    _Up and Atom_, Jade Tan-Holmes gives a fantastic explanation of ["Why Pure
    Information Gives Off Heat"] according to [Landauer's Principle]. To
    understand how Planck's constant and the Uncertainty Principle put a hard
    upper limit on how much information can be transmitted over a fixed period
    of time, see ["What is the maximum Bandwidth?"] with  Prof. Mike Merrifield
    and Brady Haran from _Sixty Symbols_. It's far more useful, in my opinion,
    to get a beginner's intuition for the _physicality of information_ than to
    memorize a bunch of equations for scaling systems that have no business
    being that big to start with.

[Amdahl's Law]: https://dl.acm.org/doi/10.1145/1465482.1465560
[Gunther's Universal Scalability Law]: https://arxiv.org/abs/0808.1431v2
[Landauer's Principle]: https://en.wikipedia.org/wiki/Landauer%27s_principle
["Why Pure Information Gives Off Heat"]: https://www.youtube.com/watch?v=XY-mbr-aAZE
["What is the maximum Bandwidth?"]: https://www.youtube.com/watch?v=0OOmSyaoAt0

To that point, it remains to be seen if the abstractions of scalability can
survive eventual contact with reality – _the cloud falling back down to earth_,
so to speak. Computational abstractions do incur physical costs and real-world
consequences, and there are practical limits to the scale of their application,
even if they encompass theoretical infinities. The need for sane limits on
computational scaling could not be more acute than in the face of our
accelerating climate crisis and the rising number of geopolitical conflicts
spawned by competition over finite energy and mineral resources. Indeed, such
resources will never be adequate to the computational demands of today's tech
moguls, if left to set their own limits. When Microsoft announces [it will
reopen Three Mile Island] to power its large language models, _this is the cloud
falling back down to earth_. When companies like Apple, Tesla and Dell are
willing to pay millions of dollars in legal fees each year so they can keep
[extracting the conflict minerals] that power our smartphones, electric
vehicles, and other devices, _this too is the cloud falling back down to earth_.

[it will reopen Three Mile Island]:
    https://www.npr.org/2024/09/20/nx-s1-5120581/three-mile-island-nuclear-power-plant-microsoft-ai
[extracting the conflict minerals]:
    https://arstechnica.com/tech-policy/2024/03/apple-and-other-firms-dont-have-to-compensate-victims-of-forced-child-labor/

## A Measure of Social Control
Beyond the clear perils to our planet's climate and natural ecosystems, rapid
scaling also threatens our social and cultural ecosystems. When big tech
companies talk about scalability, they might have in mind scaling the production
of our physical needs and wants (e.g., GrubHub, Apple, Tesla), scaling the
market for those products (e.g., Amazon, AdSense, Square), scaling the creative
arts and our cultural identities (e.g., Netflix, Spotify, YouTube), or scaling
the web of social relations bound up in all of that (e.g., Facebook, LinkedIn,
Tinder). But when these processes are scaled by algorithmic abstraction, some
essential quality of our social relations will always be lost.

In many ways, abstraction is just the omission of certain characteristics that
make real-world phenomena especially inscrutable to meaningful analysis. Those
details perceived as anomalous, divergent, or simply irrelevant are thrown out
while other patterns and traits are elevated in their place. All of this is done
to form a coherent model of whichever dynamics the modeler deems most
significant. As George Box once put it, "all models are wrong, but some are
useful," and abstraction can just as easily produce models that are insightful
and beneficial to society as it can throw up models that are misleading,
exploitative, or utterly meaningless. In the case of most cloud software, the
abstraction is performed by proprietary algorithms, hidden away on a remote
server somewhere that only its owners can ever see or control. Ask any content
creator who's tried to guess what thumbnail image will get them the most views,
or an SEO consultant who's racked their brain for the right combination of
keywords to improve their website's search ranking, and they'll tell you just
how futile a guessing game that can be.

Billions of decisions are being made every second on the basis of such
cloud-based abstractions, and all for the sake of somebody's model. But _whose_?
Most of those decisions are the sole prerogative of the algorithm's authors,
while the overwhelming majority of us are relegated to being the mere _objects
of their abstractions_, even if we never use the particular cloud software in
question. Users and non-users alike are seldom granted any knowledge of the
decisions being made that impact our lives, let alone any influence over how
those abstractions are formed in the first place. When the phenomenon being
abstracted away is an entire economic sector or, worse yet, society as a whole,
we forfeit a tremendous degree of agency over our social lives and our very
material existence. All that power of abstraction is essentially handed over to
just a few over-caffeinated engineers and their even fewer corporate managers.
Once in their hands they'll do whatever they deem necessary for the sake of
scale, often to the detriment of our communities and ultimately to the sole
benefit of their shareholders.

That imbalance of control is the definitive metric of scalability and the
primary rationale for scaling up so much tech infrastructure in the first place.
Another implicit assumption of scalability is that whatever measure is used to
indicate a company's total market share or asset valuation – e.g., the number of
active users, payments processed, or revenues – that value is expected to
increase at a _geometric rate_ with respect to the total number of engineers,
managers, etc, needed to achieve said increase. A mere _linear rate_ of growth
would be seen as an abject failure. Whether the market valuation is expressed in
users, dollars, or some other unit, in order to be commensurable with the number
of employees or other operating costs, they both must be measures of
socioeconomic value in one form or another. Furthermore, putting them in ratio
implies that together they represent some form of equity, or an unequal exchange
of socioeconomic value if it's presumed to be positive equity. Put less
euphemistically, this is a form of extraction, plain and simple. Furthermore, if
the projected growth rate – e.g., equity over time – must rise geometrically in
order to be deemed "scalable," then scalability is just an expression for the
rate at which a technology system can perpetuate and increase socioeconomic
inequality over time. Given the informational and communicative nature of such
systems, especially in comparison with pre-digital methods of scaling economic
production, it must be emphasized that such inequality will be at once economic
as well as social in nature, effecting both how resources are allocated and who
controls the allocation process. Scalability, in other words, must be viewed
essentially as _a measure of extractiveness and social control_.

Social control and extraction are nothing new, of course, and computers aren't
unique in their ability to scale them; for millennia prior to the invention of
integrated circuits, ancient bureaucrats did just fine with their abacuses, law
books, _quipu_, and clay tablets. Where computerized scaling differs is in the
_rate of extraction_ and the _degree or granularity of control_ it can achieve
relative to the amount of effort it requires to implement and enforce, exceeding
all previous forms by orders of magnitude. In fact, it is so far in excess of
what all the world's engineers, managers, and shareholders can ever hope to
master, at least with anything resembling intentionality or competence. In spite
of its knack at imposing itself on every facet of daily life, digital scaling is
a sloppy form of control, but it is control made no less powerful or potentially
dangerous for how ineptly it is wielded. As with many forms of
industrialization, social control through scalability is most harmful because of
the sheer bluntness of the tool, the reckless indifference of its owners, and
the unnecessarily broad sweep of its application to myriad social functions,
diverse cultures, and complex ecological niches. Like an [ocean trawler] that
obliterates square miles of seafloor habitat, along with the diversity of marine
life it sustains, just to harvest a few scallops and discard three quarters of
its total catch – so, too, scalability can cut across a wide swathe of our
social and natural environs, wreaking havoc with our lives and wasting untold
resources, while its operators scarcely pay any notice to the destruction left
in their wake.

[ocean trawler]: https://www.youtube.com/watch?v=IzG9AwlypaY

## Socializing Our Computational Abstractions
It should go without saying that scaling and abstractions of the sort described
above are deeply at odds with any vision for appropriate technology that
respects users' autonomy. Nevertheless, I still contend that abstraction can
also play a critical role in overturning those injustices. That is my whole
purpose with Runrig, after all – to develop the methodologies, relationships,
and infrastructure needed to bring more liberatory technologies into my own
community, and then, hopefully, to share them with others.

It was with that in mind that I first proposed the table below as a
rebuttal to the various abstractions imposed by venture capital funding
models. They've been normalized to such a degree in the tech industry that they
are taken for granted by most free software maintainers and advocates, including
myself at times.

|            Runrig Methodology |     | Venture Capitalism      |
| ----------------------------: | --- | :---------------------- |
|    ___Distributing_ CONTROL__ | vs. | _Scaling PRODUCTION_    |
|         ___Diffusing_ COSTS__ | vs. | _Accumulating CAPITAL_  |
| ___Expanding_ PARTICIPATION__ | vs. | _Consolidating MARKETS_ |
|       __WORKER-_organizing___ | vs. | _RENT-seeking_          |

Technology does not have to blindly _scale the production and reproduction of
our socio-economic systems_, to the exclusion of all other concerns. It's not
obliged to turn our communities into more efficient resource pumps for _capital
accumulation_. We can choose different abstractions and only decide to scale
them when we have group consensus. We can co-develop new abstractions for
__distributing control__ of our production systems more evenly, while also
__diffusing the costs__ of maintaining them. Instead of _consolidating markets_
into fewer and fewer hands, we can __expand the zone of participation__, along
with our capacity for collective action. And although we live for now under
capitalism, where technocratic _rent-seeking_ is the order of the day, we can
still choose not to reproduce those dynamics with our labor and technology.
Instead, let's use them to __organize bulwarks of worker power__ that are more
resilient to such rent-seeking efforts, as well as other forms of attack.
